{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to draw a plot of an SVM\n",
    "def plot_svc(svc, X, y, h=0.02, pad=0.25):\n",
    "    x_min, x_max = X[:, 0].min()-pad, X[:, 0].max()+pad\n",
    "    y_min, y_max = X[:, 1].min()-pad, X[:, 1].max()+pad\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    Z = svc.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.2)\n",
    "\n",
    "    plt.scatter(X[:,0], X[:,1], s=70, c=y, cmap=mpl.cm.Paired)\n",
    "    sv = svc.support_vectors_\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.ylim(y_min, y_max)\n",
    "    plt.xlabel('X1')\n",
    "    plt.ylabel('X2')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_classification(landmarks, index):\n",
    "    # filter out the landmarks needed\n",
    "    chosenLandmark = landmarks[landmarks.landmark_index==index]\n",
    "    chosenLandmark = chosenLandmark[np.isfinite(chosenLandmark['r'])]\n",
    "    \n",
    "    # create training and testing data\n",
    "    X = chosenLandmark[['pts', 'r']]\n",
    "    y = chosenLandmark['stype']\n",
    "    #y = y.replace(['mt-zrf'], 1)\n",
    "    #y = y.replace(['wt-zrf'], 0)\n",
    "    y = y.replace(['mt-at'], 1)\n",
    "    y = y.replace(['wt-at'], 0)\n",
    "\n",
    "    # check whether both classes exist\n",
    "    count_1 = chosenLandmark['stype'].str.contains('mt-at').sum()\n",
    "    #count_1 = chosenLandmark['stype'].str.contains('mt-zrf').sum()\n",
    "    count_0 = chosenLandmark['stype'].str.contains('wt-at').sum()\n",
    "    #count_0 = chosenLandmark['stype'].str.contains('wt-zrf').sum()\n",
    "\n",
    "    if (count_1 < 2 or count_0 < 2):\n",
    "        return None, None, None, None, None\n",
    "\n",
    "    # present the data\n",
    "    '''plt.figure(figsize=(8, 5))\n",
    "    plt.scatter(X.values[:,0], X.values[:,1], s=70, c=y, cmap=mpl.cm.Paired)\n",
    "    plt.xlabel('X1')\n",
    "    plt.ylabel('X2')\n",
    "    plt.show()'''\n",
    "    \n",
    "    # find the best C value by cross-validation\n",
    "    tuned_parameters = [{'C': [0.1, 1, 10]}]\n",
    "    clf = GridSearchCV(SVC(kernel='linear'), tuned_parameters, cv=10, scoring='accuracy')\n",
    "    clf.fit(X.values, y.values)\n",
    "    best_c = clf.best_params_['C']\n",
    "    \n",
    "    svc = SVC(C=best_c, kernel='linear')\n",
    "    svc.fit(X, y)\n",
    "    \n",
    "    #plot_svc(svc, X.values, y)\n",
    "    \n",
    "    prediction = svc.predict(X)\n",
    "    # print confusion matrix\n",
    "    print(\"confusion matrix: \")\n",
    "    cm = confusion_matrix(y, prediction)\n",
    "    cm_df = pd.DataFrame(cm.T, index=svc.classes_, columns=svc.classes_)\n",
    "    print(cm_df)\n",
    "    # print prediction results\n",
    "    print('Classification Accuracy Results: ')\n",
    "    ww =0\n",
    "    wm = 0\n",
    "    mm = 0\n",
    "    mw = 0\n",
    "    \n",
    "    for i in range (len(y)):\n",
    "        _y = y.values[i]\n",
    "        _p = prediction[i]\n",
    "\n",
    "        if _y==1 and _p==1:\n",
    "            mm = mm + 1\n",
    "        elif _y==1 and _p==0:\n",
    "            mw = mw + 1\n",
    "        elif _y==0 and _p==0:\n",
    "            ww = ww + 1\n",
    "        elif _y==0 and _p==1:\n",
    "            wm = wm + 1\n",
    "    \n",
    "    return svc, ww, wm, mm, mw\n",
    "\n",
    "# Read data\n",
    "data = int(input(\"Enter 0 for filling with median and 1 for filling with 2*median: \"))\n",
    "landmarks = pd.read_csv('./data/landmark_AT_filled_w_median.csv') if data==0 else pd.read_csv('./data/landmark_AT_filled_w_2median.csv')\n",
    "\n",
    "sample_id = str(input(\"Please enter sample index: \"))\n",
    "sample_id2 = str(input(\"Please enter the second sample index: \"))\n",
    "#sample_id3 = str(input(\"Please enter the third sample index: \"))\n",
    "#sample_id4= str(input(\"Please enter the fourth sample index: \"))\n",
    "\n",
    "result_file_name = str(input(\"Please enter result file name: \"))\n",
    "result_file_name2 = str(input(\"Please enter the second result file name: \"))\n",
    "#result_file_name3 = str(input(\"Please enter the third result file name: \"))\n",
    "#result_file_name4 = str(input(\"Please enter the fourth result file name: \"))\n",
    "\n",
    "#sample_ids = [sample_id, sample_id2, sample_id3, sample_id4]\n",
    "sample_ids = [sample_id, sample_id2]\n",
    "#result_file_names = [result_file_name, result_file_name2, result_file_name3, result_file_name4]\n",
    "result_file_names = [result_file_name, result_file_name2]\n",
    "\n",
    "for i in range(2):\n",
    "\tresult_file_name = result_file_names[i]\n",
    "\tsample_id = sample_ids[i]\n",
    "\n",
    "\tresult_file = open(result_file_name, 'w') \n",
    "\tresult_file.write('landmark_index, pred, ww, wm, mm, mw\\n')\n",
    "\t \n",
    "\tsample = landmarks[landmarks.sample_index==sample_id]\n",
    "\tlandmark_ids = sample['landmark_index']\n",
    "\n",
    "\tresults = []\n",
    "\tleave_one_out = landmarks[landmarks.sample_index!=sample_id]\n",
    "\tfor l in landmark_ids.values:\n",
    "\t    print (\"=======================================\")\n",
    "\t    print (\"landmark: \", str(l))\n",
    "\t    svc, ww, wm, mm, mw = svm_classification(leave_one_out, l)\n",
    "\t    if (svc is None):\n",
    "\t        print(\"One of the classes have too few samples for this landmark, so skipping it.\")\n",
    "\t        continue\n",
    "\t    prediction = svc.predict(sample[sample.landmark_index==l][['pts', 'r']])\n",
    "\t    result = ', '.join(str(x) for x in [l, prediction[0], ww, wm, mm, mw]) + '\\n'\n",
    "\t    results.append((l, prediction[0], ww, wm, mm, mw))\n",
    "\t    print(results)\n",
    "\n",
    "\t    result_file.write(result)\n",
    "\t   \n",
    "     result_file.close() \n",
    "'''print (\"=======================================\")\n",
    "print(\"SAMPLE REPORT\")\n",
    "r_sig = []\n",
    "for svm in results:\n",
    "    if svm[2]>0.5:\n",
    "        r_sig.append(svm)\n",
    "\n",
    "print(\"The sample has\", str(len(results)), \" landmarks.\")\n",
    "print(str(len(r_sig)), \" landmarks have f1 score larger than 0.5.\")\n",
    "\n",
    "one = []\n",
    "zero = []\n",
    "for svm in r_sig:\n",
    "    if svm[1]==1:\n",
    "        one.append(svm)\n",
    "    else:\n",
    "        zero.append(svm)\n",
    "\n",
    "print(\"One was voted \", str(len(one)), \" times.\")\n",
    "print(\"Zero was voted \", str(len(zero)), \" times.\")'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
